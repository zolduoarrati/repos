{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing packages\n",
    "* pip install lightgbm\n",
    "* conda install -c conda-forge xgboost\n",
    "* pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stack OverFlow: EDA & ML**  \n",
    "\n",
    "**Elijah Zolduoarrati**  \n",
    "**Approaches and Techniques:**\n",
    "\n",
    "* EDA with Pandas and Seaborn\n",
    "* Find features with strong correlation to target variables questions and answers\n",
    "* Data preprocessing, converting categorical features mainly (country) to numerical\n",
    "* apply the basic Regression models of sklearn \n",
    "* use gridsearchCV to find the best parameters for each model\n",
    "* compare the performance of the Regressors and choose best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The notebook is organized as follows:**\n",
    "\n",
    "* **[Part 0: Imports, Settings and switches, Global functions](#Part-0-:-Imports,-Settings,-Functions)**  \n",
    "* import libraries  \n",
    "* settings for number of cross validations  \n",
    "* define functions that are used often\n",
    "\n",
    "* **[Part 1: Exploratory Data Analysis](#Part-1:-Exploratory-Data-Analysis)**  \n",
    "1.1 Get an overview of the features (numerical and categorical) and first look on the target variables questions and answers\n",
    "[shape, info, head and describe](#shape,-info,-head-and-describe)  \n",
    "[Distribution of the target variable Q](#The-target-variable-:-Distribution-of-questions-and-answers)  \n",
    "[Numerical and Categorical features](#Numerical-and-Categorical-features)  \n",
    "[List of features with missing values](#List-of-features-with-missing-values) and Filling missing values using [log transform](#log-transform)  \n",
    "1.2 Relation of all features to target questions and answers  \n",
    "[Seaborn regression plots for numerical features](#Plots-of-relation-to-target-for-all-numerical-features)  \n",
    "[List of numerical features and their correlation coefficient to target](#List-of-numerical-features-and-their-correlation-coefficient-to-target)  \n",
    "[Seaborn boxplots for categorical features](#Relation-to-questions-and-answers-for-all-categorical-features)  \n",
    "[List of categorical features and their unique values](#List-of-categorical-features-and-their-unique-values)  \n",
    "1.3 Determine the columns that show strong correlation to target  \n",
    "[Correlation matrix 1](#Correlation-matrix-1) : all numerical features determine features with largest correlation to questions and answers\n",
    "\n",
    "* **[Part 2: Data wrangling](#Part-2:-Data-wrangling)**  \n",
    "[Dropping all columns with weak correlation to questions and answers](#Dropping-all-columns-with-weak-correlation-to-questions-and-answers)  \n",
    "[Convert categorical columns to numerical](#Convert-categorical-columns-to-numerical)  \n",
    "[Checking correlation to SalePrice for the new numerical columns](#Checking-correlation-to-questions-and-answers-for-the-new-numerical-columns)  \n",
    "use only features with strong correlation to target  \n",
    "[Correlation Matrix 2 (including converted categorical columns)](#Correlation-Matrix-2-:-All-features-with-strong-correlation-to-questions-and-answers)  \n",
    "Create datasets for ML algorithms:                                                                          \n",
    "[OneHotEncoder](#OneHotEncoder)  \n",
    "[StandardScaler](#StandardScaler)\n",
    "\n",
    "* **[Part 3: Scikit-learn basic regression models and comparison of results](#Part-3:-Scikit-learn-basic-regression-models-and-comparison-of-results)**  \n",
    "implement GridsearchCV with RMSE metric for Hyperparameter tuning for these models from sklearn:  \n",
    "[Linear Regression](#Linear-Regression)  \n",
    "[Ridge](#Ridge)  \n",
    "[Lasso](#Lasso)  \n",
    "[Elastic Net](#Elastic-Net)  \n",
    "[Stochastic Gradient Descent](#SGDRegressor)  \n",
    "[DecisionTreeRegressor](#DecisionTreeRegressor)  \n",
    "[Random Forest Regressor](#RandomForestRegressor)  \n",
    "[KNN Regressor](#KNN-Regressor)  \n",
    "Baed on RMSE metric, compare performance of the regressors with their optimized parameters, then explore correlation of the predictions and make submission with mean of best models plot comparison:             \n",
    "[RMSE of all models](#Comparison-plot:-RMSE-of-all-models)  \n",
    "[Correlation of model results](#Correlation-of-model-results)  \n",
    "Mean of best models\n",
    "\n",
    "\n",
    "Note on scores:  \n",
    "Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed questions and answers. (Taking logs means that errors in predicting questions and answers will affect the result equally.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 : Imports, Settings, Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing Lib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Math Lib for some statistics\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# df preprocessing Lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('max_columns', 105)\n",
    "\n",
    "# AI preprocessing lib\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# ML Lib\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "# warning supressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "#importing necessary models and libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Settings and switches**\n",
    "\n",
    "**Here we can choose settings for optimal performance and runtime. For example, nr_cv sets the number of cross validations used in GridsearchCV, and min_val_corr is the minimum value for the correlation coefficient to the target (only features with larger correlation will be used).** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the number of cross validations used in the Model part \n",
    "nr_cv = 5\n",
    "\n",
    "# switch for using log values for SalePrice and features     \n",
    "use_logvals = 1    \n",
    "# target used for correlation \n",
    "target_1 = 'questions'\n",
    "target_2 = 'answers'    \n",
    "# only columns with correlation above this threshold value  \n",
    "# are used for the ML Regressors in Part 3\n",
    "min_val_corr = 0.4    \n",
    "    \n",
    "# switch for dropping columns that are similar to others already used and show a high correlation to these     \n",
    "drop_similar = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initiate functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_score(grid):\n",
    "    \n",
    "    best_score = np.sqrt(-grid.best_score_)\n",
    "    print(best_score)    \n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_estimator_)\n",
    "    return best_score\n",
    "\n",
    "def print_cols_large_corr(df, nr_c, targ) :\n",
    "    corr = df.corr()\n",
    "    corr_abs = corr.abs()\n",
    "    print (corr_abs.nlargest(nr_c, targ)[targ])\n",
    "\n",
    "def plot_corr_matrix(df, nr_c, targ) :\n",
    "    \n",
    "    corr = df.corr()\n",
    "    corr_abs = corr.abs()\n",
    "    cols = corr_abs.nlargest(nr_c, targ)[targ].index\n",
    "    cm = np.corrcoef(df[cols].values.T)\n",
    "\n",
    "    plt.figure(figsize=(nr_c/1.5, nr_c/1.5))\n",
    "    sns.set(font_scale=1.25)\n",
    "    sns.heatmap(cm, linewidths=1.5, annot=True, square=True, \n",
    "                fmt='.2f', annot_kws={'size': 10}, \n",
    "                yticklabels=cols.values, xticklabels=cols.values\n",
    "               )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import check_output, call \n",
    "print(check_output([\"dir\", \"C:\\\\Users\\\\alamo248\\\\Downloads\\\\Data\\\\all_uptt.csv\"],shell=True).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data into dataframe\n",
    "df =  pd.read_csv('C://Data/all_upt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtitute missing values by zero\n",
    "#df = df.fillna(0)\n",
    "#Displaying modified dataframe\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a variable vector\n",
    "df = df.iloc[:,[0,6,7,8,9,10,11,12,13,14,15,16,17]]\n",
    "# Or\n",
    "# vec = df.loc[:,['Id','DisplayName','Location','country','AboutMe_length','activity_in_months','UpVotes','DownVotes','Reputation','Views','badges','Q_comments','A_comments','P_questions','P_answers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing sets\n",
    "df_train,df_test= train_test_split(df, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Overview of features and relation to target\n",
    "\n",
    "Let's get a first overview of the train and test dataset\n",
    "* How many rows and columns are there?  \n",
    "* What are the names of the features (columns)?  \n",
    "* Which features are numerical, which are categorical?  \n",
    "* How many values are missing?  \n",
    "The **shape** and **info** methods answer these questions. Whereas, the **head** displays some rows of the dataset **describe** gives a summary of the statistics (only for numerical columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape, Info, Head & Describe -----> Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*100)\n",
    "print('training sample size')\n",
    "print(df_train.shape)\n",
    "print('-'*100)\n",
    "print('testing sample size')\n",
    "print(df_test.shape)\n",
    "print('-'*100)\n",
    "print('training sample features description')\n",
    "print(df_train.info())\n",
    "print('-'*100)\n",
    "print('testing sample features description')\n",
    "print(df_train.info())\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It seems like the trainning and tesing dataframe *(df)* vector *(vec)* consists of 13 columns (12 features excluding Id), as for the training df vec, it has 112147 entries (number of rows). On the other hand,  df test vec has 28037 entries.  \n",
    "* There are lots of info that is probably related to the dependent variables (target) questions and answers such as badges, reputaion, etc...   \n",
    "* Maybe other features are not so important for predicting the target, also there might be a strong correlation for some of the features (like activity_in_month).\n",
    "* There are missing in some columns and it seems some countries tend to have more missing data than others, we are going to deal with missing data accordingly in a later stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying a sample from the training dataframe\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying a descriptive stats regarding the training dataframe \n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying a sample from the testing dataframe\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying a descriptive stats regarding the testing dataframe\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of target variables (Questions and Answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimising plots size\n",
    "# data = np.random.normal(0, 1, 3)\n",
    "# array([-1.18878589,  0.59627021,  1.59895721])\n",
    "# ploty = plt.figure(figsize=(20, 15))\n",
    "# sns.boxplot(x=data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ conversion error prevention **\n",
    "# df_train = df_train.fillna(0)\n",
    "# Seaborn 0_0\n",
    "print('-'*100)\n",
    "print('-'*100)\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.distplot(df_train['P_questions'].dropna());\n",
    "# skewness and Kurtosis\n",
    "print(\"Skewness: %f\" % df_train['P_questions'].skew());\n",
    "print(\"Kurtosis: %f\" % df_train['P_questions'].kurt());\n",
    "print('-'*100)\n",
    "print('-'*100)\n",
    "# ValueError: cannot convert float NaN to integer --- Error --- convertion is required ---> utilising fillna in early phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('-'*100)\n",
    "print('-'*100)\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.distplot(df_train['P_answers'].dropna());\n",
    "# skewness and Kurtosis\n",
    "print(\"Skewness: %f\" % df_train['P_answers'].skew());\n",
    "print(\"Kurtosis: %f\" % df_train['P_answers'].kurt());\n",
    "print('-'*100)\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see, the target variable for both questions and answers is not normally distributed. \n",
    "* This behaviour can leads to performance reduction in the ML regression modeling due the fact that some models assume normal distribution.\n",
    "* Therfore a log transformation is required(see sklearn info on preprocessing) to enhance distribution visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide = 'ignore')\n",
    "# vec = df_train.loc[:,['P_questions']]\n",
    "df_train['Questions_log'] = np.where(df_train.loc[:,['P_questions']]>0, np.log(df_train.loc[:,['P_questions']]), 0)\n",
    "\n",
    "# # alternative implementation -- a bit more typing but avoids warnings.\n",
    "# loc = np.where(myarray>0)\n",
    "# result2 = np.zeros_like(myarray, dtype=float)\n",
    "# result2[loc] =np.log(myarray[loc])\n",
    "\n",
    "# # answer from Enrico...\n",
    "# myarray= np.random.randint(10,size=10)\n",
    "# result = np.where(myarray>0, np.log(myarray), 0)\n",
    "\n",
    "# # check it is giving right solution:\n",
    "# print(np.allclose(result, result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, Questions_log], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating a log feature for dependent varaiables\n",
    "# df_train['Questions_log'] = np.log(df_train['P_questions'])\n",
    "# df_train['Answers_log'] = np.log(df_train['P_answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['Questions_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,15))\n",
    "# sns.distplot(df_train['Questions_log'].dropna())\n",
    "# #sns.distplot(df_train['P_answers'].dropna());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create the independent variable vector\n",
    "# x = df.iloc[:,6:15].values\n",
    "# # Question dependent variable vector \n",
    "# y = df.iloc[:, -2:-1].values\n",
    "# # Answer dependent variable vector \n",
    "# z = df.iloc[:,-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create labelEncoder object to transform categorical values into integers\n",
    "# x[:, 0] = LabelEncoder().fit_transform(x[:, 0])\n",
    "# y = LabelEncoder().fit_transform(y)\n",
    "# z = LabelEncoder().fit_transform(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating OneHotEncoder object to transform integer categorical values into dummy categorical\n",
    "# x = OneHotEncoder(categorical_features=[0]).fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training and testing sets\n",
    "# x_train,x_test,y_train,y_test,z_train,z_test = train_test_split(x,y,z, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feature scaling\n",
    "# sc_x = StandardScaler()\n",
    "# x_train = sc_x.fit_transform(x_train)\n",
    "# x_test = sc_x.transform(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
